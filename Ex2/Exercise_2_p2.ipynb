{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the binary classification algorithm for the digits 3 and 4 of MNIST dataset.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Download the MNIST dataset from [kaggle.com/datasets/animatronbot/mnist-digit-recognizer](https://kaggle.com/datasets/animatronbot/mnist-digit-recognizer) and load it into memory by following the steps we did in the PCA class. When loaded into memory, this dataset appears as an array with shape $ (42000, 785) $, containing the flattened version of $ 42000 \\space 28 \\times 28 $ grayscale handwritten digits, plus a column representing the true class of the corresponding digit. By pre-processing the data as we did in class, you should obtain a matrix $ X $ containing the flattened digits, with shape $ (784, 42000) $, and a vector $ Y $ of the associated digit value, with a shape of $ (42000,) $.\n",
    "\n",
    "2. Write a function taking as input an index value $ idx $ and visualizes the image of $ X $ in the corresponding index (i.e. $ X[idx, :] $). Use the function `plt.imshow`.\n",
    "\n",
    "3. Filter from $ X $ only those elements that correspond to digits 3 or 4. This can be done, for example, by using the boolean slicing of numpy arrays, as already discussed in class.\n",
    "\n",
    "4. Split the obtained dataset into training and testing in a proportion of $ 80\\%-20\\% $. From now on, we will only consider the training set. The test set will be only used at the end of the exercise to test the algorithm.\n",
    "\n",
    "5. Call $ X_1 $ and $ X_2 $ the submatrices of the training set, filtered by the two selected digits, corresponding to those elements associated with number 3 (class $ C_1 $), and with number 4 (class $ C_2 $).\n",
    "\n",
    "6. Compute the SVD decomposition of $ X_1 $ and $ X_2 $ with `np.linalg.svd(matrix, full_matrices=False)` and denote the $ U $-part of the two decompositions as $ U_1 $ and $ U_2 $.\n",
    "7.\tTake an unknown digit $ x $ from the test set, and compute: $ x_1^{\\perp}=U_1(U_1^Tx)$ and $x_2^{\\perp}=U_2(U_2^Tx)$\n",
    "   \n",
    "8.\tCompute the distances $ d_1 = ||x-x_1^{\\perp}||_2 $ and $  d_2 = ||x-x_2^{\\perp}||_2 $, and classify $ x $ as $ C_1 $ if $ d_1 < d_2 $, as $ C_2 $ if $ d_2 < d_1 $.\n",
    "9.\tRepeat the experiment for different values of $ x $ in the test set. Compute the misclassification rate for this algorithm.\n",
    "10.\tRepeat the experiment for different digits other than 3 or 4. Is there a relationship between the visual similarity of the digits and the classification error?\n",
    "11.\tComment on the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the MNIST dataset from [kaggle.com/datasets/animatronbot/mnist-digit-recognizer](https://kaggle.com/datasets/animatronbot/mnist-digit-recognizer) and load it into memory by following the steps we did in the PCA class. When loaded into memory, this dataset appears as an array with shape $ (42000, 785) $, containing the flattened version of $ 42000\\space 28 \\times 28 $ grayscale handwritten digits, plus a column representing the true class of the corresponding digit. By pre-processing the data as we did in class, you should obtain a matrix $ X $ containing the flattened digits, with shape $ (784, 42000) $, and a vector $ Y $ of the associated digit value, with a shape of $ (42000,) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# print first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of X is: (784, 42000), and dimension of Y is: (42000,)\n"
     ]
    }
   ],
   "source": [
    "# converting data into a matrix\n",
    "data = np.array(data)\n",
    "\n",
    "# X only contains the pixels for each without the label\n",
    "# that is in the first column \n",
    "X = data[:,1:]\n",
    "# transpose the matrix to be coherent with the notation\n",
    "X = X.T\n",
    "\n",
    "# true values (label) of digits in matrix Y\n",
    "Y = data[:,0]\n",
    "\n",
    "print(f\"dimension of X is: {X.shape}, and dimension of Y is: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function taking as input an index value $ idx $ and visualizes the image of $ X $ in the corresponding index (i.e. $ X[idx, :] $). Use the function `plt.imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The associated digit is: 1\n"
     ]
    }
   ],
   "source": [
    "def show_img(idx, X):\n",
    "    # first, we take the flattened matrix X and reshape it in a 28x28 pixels image\n",
    "    # take all the rows of the column 'idx', such that i take all the pixels of the image at index 'idx'\n",
    "    img = X[:, idx]\n",
    "    img = np.reshape(img, (28,28))\n",
    "\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "# print the 15th image of the dataset\n",
    "idx = 15\n",
    "show_img(idx, X)\n",
    "print(f\"The associated digit is: {Y[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Filter from $ X $ only those elements that correspond to digits 3 or 4. This can be done, for example, by using the boolean slicing of numpy arrays, as already discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the filtered matrix X is: (784, 8423) and the shape of filtered matrix Y is: (8423,)\n"
     ]
    }
   ],
   "source": [
    "# filtering only digits corresponding to 3 or 4\n",
    "def filtering_n1_or_n2(X, Y, n1, n2):\n",
    "    # creating a mask\n",
    "    img_filter = (Y==n1) | (Y==n2)\n",
    "\n",
    "    # take all the images (pixels) corrisponding at the indexes where img_filter is true  \n",
    "    filter_X = X[:,img_filter]\n",
    "    filter_Y = Y[img_filter]\n",
    "\n",
    "    return (filter_X, filter_Y)\n",
    "\n",
    "filter_X, filter_Y = filtering_n1_or_n2(X,Y, 3, 4)\n",
    "print(f\"The shape of the filtered matrix X is: {filter_X.shape} and the shape of filtered matrix Y is: {filter_Y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split the obtained dataset into training and testing in a proportion of $ 80\\%-20\\% $. From now on, we will only consider the training set. The test set will be only used at the end of the exercise to test the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 6738) (784, 1685)\n"
     ]
    }
   ],
   "source": [
    "def split_data(X, Y, n_train):    # numbers of images on which work\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    # arrays of numbers\n",
    "    idx = np.arange(N)\n",
    "    # shuffle datas in order to have random training and test data\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    # indexes \n",
    "    train_idx = idx[:n_train]\n",
    "    test_idx = idx[n_train:]\n",
    "    \n",
    "    # X matrix\n",
    "    X_train = X[:, train_idx]\n",
    "    X_test = X[:, test_idx]\n",
    "    \n",
    "    # Y matrix\n",
    "    Y_train = Y[train_idx]\n",
    "    Y_test = Y[test_idx]\n",
    "    \n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "\n",
    "\n",
    "# 80% of images \n",
    "n = int(filter_X.shape[1] * 0.8)\n",
    "(X_train, Y_train), (X_test, Y_test) = split_data(filter_X, filter_Y, n)\n",
    "    \n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Call $ X_1 $ and $ X_2 $ the submatrices of the training set, filtered by the two selected digits, corresponding to those elements associated with number 3 (class $ C_1 $), and with number 4 (class $ C_2 $)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subclasses(n1, n2, X_train, Y_train):\n",
    "    # dividing the training set in two subsets,\n",
    "    # containing the images for each number\n",
    "    X_1 = X_train.T[Y_train == n1]\n",
    "    X_2 = X_train.T[Y_train == n2]\n",
    "\n",
    "    # transpose X_1 and X_2\n",
    "    X_1 = X_1.T\n",
    "    X_2 = X_2.T\n",
    "    \n",
    "    return X_1, X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6. Compute the SVD decomposition of $ X_1 $ and $ X_2 $ with `np.linalg.svd(matrix, full_matrices=False)` and denote the $ U $-part of the two decompositions as $ U_1 $ and $ U_2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_computing(n1, n2, X_train, Y_train):\n",
    "    X_1, X_2 = subclasses(n1, n2, X_train, Y_train)\n",
    "    # compute SVD of X_1\n",
    "    U_1, s_1, VT_1 = np.linalg.svd(X_1, full_matrices=False)\n",
    "    U_2, s_2, VT_2 = np.linalg.svd(X_2, full_matrices=False)\n",
    "\n",
    "    return U_1, U_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tTake an unknown digit $ x $ from the test set, and compute: $ x_1^{\\perp}=U_1(U_1^Tx)$ and $x_2^{\\perp}=U_2(U_2^Tx)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_projection(U_1, U_2, x):\n",
    "    x_1 = U_1 @ (U_1.T @ x)\n",
    "    x_2 = U_2 @ (U_2.T @ x)\n",
    "    return (x_1, x_2)\n",
    "\n",
    "\n",
    "# select unknown image and its true value\n",
    "x = X_test[:, 5]\n",
    "y = Y_test[5]\n",
    "\n",
    "# SVD on the training set \n",
    "U_1, U_2 = SVD_computing(3, 4, X_train, Y_train)\n",
    "\n",
    "# Data projection \n",
    "x_1, x_2 = x_projection(U_1, U_2, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tCompute the distances $ d_1 = ||x-x_1^{\\perp}||_2 $ and $  d_2 = ||x-x_2^{\\perp}||_2 $, and classify $ x $ as $ C_1 $ if $ d_1 < d_2 $, as $ C_2 $ if $ d_2 < d_1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 4 classified as C_2 (class 4)\n"
     ]
    }
   ],
   "source": [
    "def compute_dist(x, x_1, x_2):\n",
    "    # Compute distance between the real digit\n",
    "    # and our projection\n",
    "    d_1 = np.linalg.norm(x-x_1, 2)\n",
    "    d_2 = np.linalg.norm(x-x_2, 2)\n",
    "    return d_1, d_2\n",
    "\n",
    "d_1, d_2 = compute_dist(x, x_1, x_2)\n",
    "\n",
    "# classification\n",
    "if(d_1 < d_2):\n",
    "    print(f\"number {y} classified as C_1 (class 3)\")\n",
    "else:\n",
    "    print(f\"number {y} classified as C_2 (class 4)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tRepeat the experiment for different values of $ x $ in the test set. Compute the misclassification rate for this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1685 tries, the misclassification error for the digit 3 and 4 is 7.48%\n"
     ]
    }
   ],
   "source": [
    "def misclassification_error(X_test, Y_test, n1, n2, U_1, U_2):\n",
    "    MR = 0\n",
    "    \n",
    "    # for each image in the X_test\n",
    "    # compute the misclassification\n",
    "    for i in range(X_test.shape[1]):\n",
    "        x = X_test[:, i]\n",
    "        y = Y_test[i]\n",
    "        \n",
    "        x_1, x_2 = x_projection(U_1, U_2, x)\n",
    "        \n",
    "        d_1, d_2 = compute_dist(x, x_1, x_2)\n",
    "        \n",
    "        if d_1 < d_2 and y == n2:\n",
    "            MR += 1\n",
    "        elif d_1 > d_2 and y == n1:\n",
    "            MR += 1\n",
    "\n",
    "\n",
    "    n_test = X_test.shape[1]\n",
    "    error = round((MR/n_test)*100, 2)\n",
    "    print(f\"Out of {n_test} tries, the misclassification error for the digit {n1} and {n2} is {error}%\") \n",
    "    return error\n",
    "\n",
    "MR = misclassification_error(X_test, Y_test, 3, 4, U_1, U_2)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tRepeat the experiment for different digits other than 3 or 4. Is there a relationship between the visual similarity of the digits and the classification error?\n",
    "11.\tComment on the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship between the visual similarity of the digits and the error rate is an interesting aspect. If the chosen digits are visually similar, the error rate will likely be higher, as the algorithm may confuse the digits. For example, digits like 1 and 5 are quite distinct, so we might expect a lower error rate, whereas digits like 3 and 8 might be confused due to their visual similarity, leading to a higher error rate.\n",
    "\n",
    "Indeed, as we have seen so far comparing the number 3 and 4, as they are visually pretty different, the error rate is quite low (15%-20%).\n",
    "\n",
    "Let's compute the error rate for these two pairs of number (1,5) and (3,8) and then i will discuss on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair(n1,n2):\n",
    "    # computing filtering for the specific pair\n",
    "    filter_X, filter_Y = filtering_n1_or_n2(X,Y, n1, n2)\n",
    "\n",
    "    # computing train and test data\n",
    "    n = int(filter_X.shape[1] * 0.8)\n",
    "    (X_train, Y_train), (X_test, Y_test) = split_data(filter_X, filter_Y, n)\n",
    "\n",
    "    # compute SVD\n",
    "    U_1, U_2 = SVD_computing(n1, n2, X_train, Y_train)\n",
    "\n",
    "    # compute misclassification error\n",
    "    MR = misclassification_error(X_test, Y_test, n1, n2, U_1, U_2)\n",
    "\n",
    "    return MR\n",
    "    \n",
    "def main():\n",
    "    # different pairs of digits\n",
    "    MR1 = pair(1,5)\n",
    "    MR2 = pair(3,8)\n",
    "    MR3 = pair(3,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1696 tries, the misclassification error for the digit 1 and 5 is 30.9%\n",
      "Out of 1683 tries, the misclassification error for the digit 3 and 8 is 13.55%\n",
      "Out of 1685 tries, the misclassification error for the digit 3 and 4 is 3.32%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extension of this idea to the multiple classification task is trivial. Indeed, if we have more than 2 classes (say, $k$ different classes) $C_1,...,C_k$, we just need to repeat the same procedure as before for each matrix $X_1,...,X_k$ to obtain the distances $d_1,...,d_k$. Then, the new digit $x$  from the test set will be classified as $C_i$ if $d_i$ is lower than $d_j$ for each $j=1,...,k$.\n",
    "\n",
    "Repeat the exercise above with a 3-digit example. Comment the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 2534 tries, the misclassification error for the digit 1, 5 and 9, is 31.77%\n"
     ]
    }
   ],
   "source": [
    "# example of 3 digits\n",
    "n1, n2, n3 = 1, 5, 9\n",
    "\n",
    "def filtering_n1_or_n2_n3(X, Y, n1, n2, n3):\n",
    "    img_filter = (Y==n1) | (Y==n2) | (Y==n3)\n",
    "\n",
    "    filter_X = X[:,img_filter]\n",
    "    filter_Y = Y[img_filter]\n",
    "\n",
    "    return (filter_X, filter_Y)\n",
    "\n",
    "filter_X, filter_Y = filtering_n1_or_n2_n3(X, Y, n1, n2, n3)\n",
    "(X_train, Y_train), (X_test, Y_test) = split_data(filter_X, filter_Y, int(filter_X.shape[1] * 0.8))\n",
    "\n",
    "def subclasses(n1, n2, n3, X_train, Y_train):\n",
    "    X_1 = X_train.T[Y_train == n1]\n",
    "    X_2 = X_train.T[Y_train == n2]\n",
    "    X_3 = X_train.T[Y_train == n3]\n",
    "\n",
    "    # transpose X_1 and X_2\n",
    "    X_1 = X_1.T\n",
    "    X_2 = X_2.T\n",
    "    X_3 = X_3.T\n",
    "    \n",
    "    return X_1, X_2, X_3\n",
    "\n",
    "\n",
    "def SVD_computing(n1, n2, n3, X_train, Y_train):\n",
    "    X_1, X_2, X_3 = subclasses(n1, n2, n3, X_train, Y_train)\n",
    "\n",
    "    U_1, s_1, VT_1 = np.linalg.svd(X_1, full_matrices=False)\n",
    "    U_2, s_2, VT_2 = np.linalg.svd(X_2, full_matrices=False)\n",
    "    U_3, s_3, VT_3 = np.linalg.svd(X_3, full_matrices=False)\n",
    "\n",
    "    return U_1, U_2, U_3\n",
    "\n",
    "def x_projection(U_1, U_2, U_3, x):\n",
    "    x_1 = U_1 @ (U_1.T @ x)\n",
    "    x_2 = U_2 @ (U_2.T @ x)\n",
    "    x_3 = U_3 @ (U_3.T @ x)\n",
    "\n",
    "    return (x_1, x_2, x_3)\n",
    "\n",
    "def compute_dist(x, x_1, x_2, x_3):\n",
    "    d_1 = np.linalg.norm(x-x_1, 2)\n",
    "    d_2 = np.linalg.norm(x-x_2, 2)\n",
    "    d_3 = np.linalg.norm(x-x_3, 2)\n",
    "    return d_1, d_2, d_3\n",
    "\n",
    "U_1, U_2, U_3 = SVD_computing(n1, n2, n3, X_train, Y_train)\n",
    "\n",
    "def misclassification_error(X_test, Y_test, n1, n2, n3, U_1, U_2, U_3):\n",
    "    MR = 0\n",
    "    for i in range(X_test.shape[1]):\n",
    "        x = X_test[:, i]\n",
    "        y = Y_test[i]\n",
    "        \n",
    "        x_1, x_2, x_3 = x_projection(U_1, U_2, U_3, x)\n",
    "        \n",
    "        d_1, d_2, d_3 = compute_dist(x, x_1, x_2, x_3)\n",
    "        \n",
    "        if d_1 < d_2 and d_1 < d_3 and y != n1:\n",
    "            MR += 1\n",
    "        elif d_2 < d_1 and d_2 < d_3 and y != n2:\n",
    "            MR += 1\n",
    "        elif d_3 < d_1 and d_3 < d_2 and y != n3:\n",
    "            MR += 1\n",
    "\n",
    "    n_test = X_test.shape[1]\n",
    "    print(f\"Out of {n_test} tries, the misclassification error for the digit {n1}, {n2} and {n3}, is {round((MR/n_test)*100, 2)}%\") \n",
    "    return round((MR/n_test)*100, 2)\n",
    "\n",
    "\n",
    "U_1, U_2, U_3 = SVD_computing(n1, n2, n3, X_train, Y_train)\n",
    "MR = misclassification_error(X_test, Y_test, n1, n2, n3, U_1, U_2, U_3) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMM_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
